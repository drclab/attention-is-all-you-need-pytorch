{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [**NLP FROM SCRATCH: TRANSLATION WITH A SEQUENCE TO SEQUENCE NETWORK AND ATTENTION**](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html#nlp-from-scratch-translation-with-a-sequence-to-sequence-network-and-attention)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is the third and final tutorial on doing “NLP From Scratch”, where we write our own classes and functions to preprocess the data to do our NLP modeling tasks. We hope after you complete this tutorial that you’ll proceed to learn how torchtext can handle much of this preprocessing for you in the three tutorials immediately following this one."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [KEY: > input, = target, < output]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\> il est en train de peindre un tableau .\n",
    "\n",
    "= he is painting a picture .\n",
    "\n",
    "< he is painting a picture ."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is made possible by the simple but powerful idea of the sequence to sequence network, in which two recurrent neural networks work together to transform one sequence to another. An encoder network condenses an input sequence into a vector, and a decoder network unfolds that vector into a new sequence."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://pytorch.org/tutorials/_images/seq2seq.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve upon this model we’ll use an attention mechanism, which lets the decoder learn to focus over a specific range of the input sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://download.pytorch.org/tutorial/data.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "home = os.environ['HOME']\n",
    "data_dir = f\"{home}/torch/\"\n",
    "file_dir = data_dir + \"data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lang:\n",
    "    def __init__(self, name) -> None:\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: 'SOS', 1: 'EOS'}\n",
    "        self.n_words = 2\n",
    "    \n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "    \n",
    "    def addSentence(self, sentence):\n",
    "        for w in sentence.split(' '):\n",
    "            self.addWord(w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s) # \\1 is the pattern in r\"([.!?])\"\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'adf ?'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalizeString(' Adf56?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_Langs(lang1, lang2, reverse=False):\n",
    "    file_name = file_dir + f\"{lang1}-{lang2}.txt\"\n",
    "    lines = (open(file_name, encoding='utf-8').\n",
    "                read().strip().split('\\n'))\n",
    "    \n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "    if reverse:\n",
    "        pairs= [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "    \n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Since there are a lot of example sentences and we want to train something quickly, we’ll trim the data set to only relatively short and simple sentences. Here the maximum length is 10 words (that includes ending punctuation) and we’re filtering to sentences that translate to the form “I am” or “He is” etc. (accounting for apostrophes replaced earlier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10  # filtering sentences with up to 10 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_Pair(p):\n",
    "    return (\n",
    "        len(p[0].split(' ')) < MAX_LENGTH and \n",
    "        len(p[1].split(' ')) < MAX_LENGTH and\n",
    "        p[1].startswith(eng_prefixes)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filter_Pair(pair)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full process for preparing the data is:\n",
    "\n",
    "1. Read text file and split into lines, split lines into pairs\n",
    "\n",
    "2. Normalize text, filter by length and content\n",
    "\n",
    "3. Make word lists from sentences in pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = read_Langs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    \n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 135842 sentence pairs\n",
      "Trimmed to 10599 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "fra 4345\n",
      "eng 2803\n"
     ]
    }
   ],
   "source": [
    "input_lang, output_lang, pairs = prepareData('eng', 'fra', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vous n etes pas differents .', 'you re no different .']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice(pairs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [The Seq2Seq Model](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html#the-seq2seq-model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A Recurrent Neural Network, or RNN, is a network that operates on a sequence and uses its own output as input for subsequent steps. A Sequence to Sequence network, or seq2seq network, or Encoder Decoder network, is a model consisting of two RNNs called the encoder and decoder. The encoder reads an input sequence and outputs a single vector, and the decoder reads that vector to produce an output sequence."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://pytorch.org/tutorials/_images/seq2seq.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Unlike sequence prediction with a single RNN, where every input corresponds to an output, the seq2seq model frees us from sequence length and order, which makes it ideal for translation between two languages. Consider the sentence “Je ne suis pas le chat noir” → “I am not the black cat”. Most of the words in the input sentence have a direct translation in the output sentence, but are in slightly different orders, e.g. “chat noir” and “black cat”. Because of the “ne/pas” construction there is also one more word in the input sentence. It would be difficult to produce a correct translation directly from the sequence of input words. With a seq2seq model the encoder creates a single vector which, in the ideal case, encodes the “meaning” of the input sequence into a single vector — a single point in some N dimensional space of sentences."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Encoder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://pytorch.org/tutorials/_images/encoder-network.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[nn.Embedding](https://medium.com/@gautam.e/what-is-nn-embedding-really-de038baadd24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size) -> None:\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        #print(input)\n",
    "        # w_embedding just needed the indices of row to do a lookup\n",
    "        embed = self.embedding(input).view(1,1,-1)\n",
    "        #print(embed.size())\n",
    "        output = embed\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_Hidden(self):\n",
    "        return torch.zeros(1,1, self.hidden_size, device=device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/1152PYf.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://pytorch.org/tutorials/_images/attention-decoder-network.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p = 0.1, max_length=MAX_LENGTH) -> None:\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embed = self.embedding(input).view(1,1,-1)\n",
    "        embed = self.dropout(embed)\n",
    "        attn_weights = F.softmax(\n",
    "                self.attn(torch.cat((embed[0], hidden[0]), 1)),\n",
    "                dim=1\n",
    "            )\n",
    "\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
    "        output = torch.cat((embed[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def init_Hidden(self):\n",
    "        return torch.zeros(1,1, self.hidden_size, device= device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Training](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html#training)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To train, for each pair we will need an input tensor (indexes of the words in the input sentence) and target tensor (indexes of the words in the target sentence). While creating these vectors we will append the EOS token to both sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indxFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indxFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = random.choice(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor, target_tensor = tensorsFromPair(pr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Tarin Model](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html#training-the-model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To train we run the input sentence through the encoder, and keep track of every output and the latest hidden state. Then the decoder is given the <SOS> token as its first input, and the last hidden state of the encoder as its first hidden state."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### “**Teacher forcing**” is the concept of using the real target outputs as each next input, instead of using the decoder’s guess as the next input. Using teacher forcing causes it to converge faster but when the trained network is exploited, it may exhibit instability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "encoder_optimizer = optim.SGD(encoder1.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.SGD(attn_decoder1.parameters(), lr=learning_rate)\n",
    "\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_Pair(\n",
    "        input_tensor,\n",
    "        target_tensor,\n",
    "        encoder,\n",
    "        encod_optim,\n",
    "        decoder,\n",
    "        decod_optim,\n",
    "        criterion,\n",
    "        max_length = MAX_LENGTH\n",
    "    ):\n",
    "    encoder_hidden = encoder.init_Hidden()\n",
    "    encod_optim.zero_grad()\n",
    "    decod_optim.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "    #print(encoder_hidden.size(), input_length, target_length)\n",
    "    encoder_outputs = torch.zeros(\n",
    "            max_length, encoder.hidden_size, device=device\n",
    "    )\n",
    "    \n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden\n",
    "        )\n",
    "        #print(encoder_output.size())\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    # print(encoder_outputs.size()) == [10, 256]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    for di in range(target_length):\n",
    "         \n",
    "        decoder_output, decoder_hidden, decoder_attn = decoder(\n",
    "            decoder_input, decoder_hidden, encoder_outputs\n",
    "        )\n",
    "\n",
    "        loss += criterion(decoder_output, target_tensor[di])\n",
    "        decoder_input = target_tensor[di]\n",
    "        \n",
    "    loss.backward()\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.908318519592285"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Pair(input_tensor, target_tensor, \n",
    "            encoder1, encoder_optimizer, \n",
    "            attn_decoder1, decoder_optimizer, \n",
    "            criterion)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_Iterations(\n",
    "        n_iters,\n",
    "        print_every = 1000,\n",
    "        plot_every = 100\n",
    "    ):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0\n",
    "    plot_loss_total = 0\n",
    "\n",
    "    train_pairs = [\n",
    "        tensorsFromPair(random.choice(pairs)) for i in range(n_iters)\n",
    "    ]\n",
    " \n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        train_pair = train_pairs[iter -1]\n",
    "        input_tensor = train_pair[0]\n",
    "        target_tensor = train_pair[1]\n",
    "\n",
    "        loss = train_Pair(input_tensor, target_tensor, \n",
    "                            encoder1, encoder_optimizer, \n",
    "                            attn_decoder1, decoder_optimizer, \n",
    "                             criterion)\n",
    "\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print(\n",
    "                '%s (%d, %d%%) %.4f' % (\n",
    "                    timeSince(start, iter / n_iters),\n",
    "                    iter,\n",
    "                    iter / n_iters * 100,\n",
    "                    print_loss_avg\n",
    "                )\n",
    "            )\n",
    "            print_loss_total = 0\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    return plot_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1m 41s (- 125m 42s) (1000, 1%) 3.3710\n",
      "3m 27s (- 126m 15s) (2000, 2%) 2.6703\n",
      "5m 7s (- 122m 51s) (3000, 4%) 2.4327\n",
      "6m 42s (- 119m 0s) (4000, 5%) 2.2852\n",
      "8m 20s (- 116m 48s) (5000, 6%) 2.2316\n",
      "10m 1s (- 115m 19s) (6000, 8%) 2.1339\n",
      "11m 28s (- 111m 26s) (7000, 9%) 1.9757\n",
      "12m 54s (- 108m 10s) (8000, 10%) 1.9681\n",
      "14m 21s (- 105m 17s) (9000, 12%) 1.8674\n",
      "15m 47s (- 102m 35s) (10000, 13%) 1.7822\n",
      "17m 20s (- 100m 54s) (11000, 14%) 1.7301\n",
      "18m 54s (- 99m 17s) (12000, 16%) 1.6526\n",
      "20m 19s (- 96m 56s) (13000, 17%) 1.6751\n",
      "21m 44s (- 94m 45s) (14000, 18%) 1.6082\n",
      "23m 10s (- 92m 43s) (15000, 20%) 1.5617\n",
      "24m 36s (- 90m 44s) (16000, 21%) 1.4597\n",
      "26m 19s (- 89m 47s) (17000, 22%) 1.4735\n",
      "28m 21s (- 89m 46s) (18000, 24%) 1.4329\n",
      "29m 57s (- 88m 16s) (19000, 25%) 1.3692\n",
      "31m 29s (- 86m 36s) (20000, 26%) 1.3298\n",
      "33m 4s (- 85m 2s) (21000, 28%) 1.3152\n",
      "34m 38s (- 83m 27s) (22000, 29%) 1.2741\n",
      "36m 14s (- 81m 55s) (23000, 30%) 1.2197\n",
      "37m 47s (- 80m 17s) (24000, 32%) 1.2301\n",
      "39m 25s (- 78m 50s) (25000, 33%) 1.1910\n",
      "41m 1s (- 77m 18s) (26000, 34%) 1.1729\n",
      "42m 44s (- 75m 58s) (27000, 36%) 1.1496\n",
      "44m 13s (- 74m 13s) (28000, 37%) 1.1125\n",
      "46m 6s (- 73m 7s) (29000, 38%) 1.0382\n",
      "47m 42s (- 71m 33s) (30000, 40%) 1.0648\n",
      "49m 16s (- 69m 56s) (31000, 41%) 1.0167\n",
      "50m 56s (- 68m 27s) (32000, 42%) 0.9715\n",
      "52m 30s (- 66m 49s) (33000, 44%) 0.9312\n",
      "54m 3s (- 65m 10s) (34000, 45%) 0.9318\n",
      "55m 37s (- 63m 34s) (35000, 46%) 0.9303\n",
      "57m 11s (- 61m 57s) (36000, 48%) 0.9097\n",
      "58m 47s (- 60m 22s) (37000, 49%) 0.9032\n",
      "60m 27s (- 58m 52s) (38000, 50%) 0.8746\n",
      "61m 49s (- 57m 4s) (39000, 52%) 0.7977\n",
      "63m 18s (- 55m 23s) (40000, 53%) 0.7786\n",
      "64m 46s (- 53m 43s) (41000, 54%) 0.7812\n",
      "66m 14s (- 52m 2s) (42000, 56%) 0.7661\n",
      "67m 41s (- 50m 22s) (43000, 57%) 0.7894\n",
      "69m 9s (- 48m 43s) (44000, 58%) 0.7380\n",
      "70m 37s (- 47m 5s) (45000, 60%) 0.7280\n",
      "72m 6s (- 45m 27s) (46000, 61%) 0.7166\n",
      "73m 33s (- 43m 49s) (47000, 62%) 0.7031\n",
      "75m 1s (- 42m 11s) (48000, 64%) 0.6575\n",
      "76m 28s (- 40m 34s) (49000, 65%) 0.6666\n",
      "77m 56s (- 38m 58s) (50000, 66%) 0.6535\n",
      "79m 24s (- 37m 22s) (51000, 68%) 0.6749\n",
      "80m 52s (- 35m 46s) (52000, 69%) 0.6391\n",
      "82m 20s (- 34m 10s) (53000, 70%) 0.6216\n",
      "83m 47s (- 32m 35s) (54000, 72%) 0.5770\n",
      "85m 14s (- 30m 59s) (55000, 73%) 0.5968\n",
      "86m 43s (- 29m 25s) (56000, 74%) 0.5687\n",
      "88m 10s (- 27m 50s) (57000, 76%) 0.5355\n",
      "89m 38s (- 26m 16s) (58000, 77%) 0.5636\n",
      "91m 5s (- 24m 42s) (59000, 78%) 0.5312\n",
      "92m 33s (- 23m 8s) (60000, 80%) 0.5322\n",
      "93m 55s (- 21m 33s) (61000, 81%) 0.5226\n",
      "95m 19s (- 19m 59s) (62000, 82%) 0.4898\n",
      "96m 43s (- 18m 25s) (63000, 84%) 0.4815\n",
      "98m 6s (- 16m 51s) (64000, 85%) 0.4729\n",
      "99m 30s (- 15m 18s) (65000, 86%) 0.4715\n",
      "101m 19s (- 13m 49s) (66000, 88%) 0.4893\n",
      "102m 56s (- 12m 17s) (67000, 89%) 0.4668\n",
      "104m 17s (- 10m 44s) (68000, 90%) 0.4716\n",
      "105m 41s (- 9m 11s) (69000, 92%) 0.4620\n",
      "106m 54s (- 7m 38s) (70000, 93%) 0.4390\n",
      "108m 41s (- 6m 7s) (71000, 94%) 0.4080\n",
      "110m 5s (- 4m 35s) (72000, 96%) 0.3923\n",
      "111m 22s (- 3m 3s) (73000, 97%) 0.3763\n",
      "112m 41s (- 1m 31s) (74000, 98%) 0.3864\n",
      "114m 10s (- 0m 0s) (75000, 100%) 0.3865\n"
     ]
    }
   ],
   "source": [
    "losses = train_Iterations(75000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc75e080040>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Evaluation](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html#evaluation)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation is mostly the same as training, but there are no targets so we simply feed the decoder’s predictions back to itself for each step. Every time it predicts a word we add it to the output string, and if it predicts the EOS token we stop there. We also store the decoder’s attention outputs for display later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    #print(sentence)\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        #print(input_tensor)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.init_Hidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0,0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)       \n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoded_words = []\n",
    "\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attn = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "\n",
    "            decoder_attentions[di] = decoder_attn.data\n",
    "\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(\n",
    "                    output_lang.index2word[topi.item()]\n",
    "                )\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_Randomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        out_words, out_attns = evaluate(encoder, decoder, pair[0])\n",
    "        out_sentence = ' '.join(out_words)\n",
    "        print('<', out_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> je suis juste a l exterieur .\n",
      "= i m right outside .\n",
      "< i m right outside . <EOS>\n",
      "> les jeans sont en rupture de stock .\n",
      "= we are sold out of jeans .\n",
      "< we are sold out of jeans . <EOS>\n",
      "> vous avez probablement raison .\n",
      "= you re probably right .\n",
      "< you re probably right . <EOS>\n",
      "> nous sommes en retard .\n",
      "= we re behind schedule .\n",
      "< we re late . <EOS>\n",
      "> nous y sommes tous ensemble .\n",
      "= we re all in this together .\n",
      "< we re all in this together . <EOS>\n",
      "> je ne vais pas te revoir .\n",
      "= i m not going to see you again .\n",
      "< i m not giving you again . <EOS>\n",
      "> nous sommes bourres .\n",
      "= we re plastered .\n",
      "< we re smashed . <EOS>\n",
      "> je suis desolee de t avoir fait peur .\n",
      "= i m sorry if i scared you .\n",
      "< i m sorry i yelled at you . <EOS>\n",
      "> vous etes influent .\n",
      "= you re influential .\n",
      "< you re skinny . <EOS>\n",
      "> tu commets une grosse erreur .\n",
      "= you re making a big mistake .\n",
      "< you re making a terrible mistake . <EOS>\n"
     ]
    }
   ],
   "source": [
    "evaluate_Randomly(encoder1, attn_decoder1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Visualizing Attention](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html#visualizing-attention)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A useful property of the attention mechanism is its highly interpretable outputs. Because it is used to weight specific encoder outputs of the input sequence, we can imagine looking where the network is focused most at each time step."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
